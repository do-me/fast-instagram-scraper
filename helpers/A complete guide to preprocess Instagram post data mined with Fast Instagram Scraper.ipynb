{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for blog post\n",
    "# [A complete guide to preprocess Instagram post data](https://geo.rocks/post/preprocessing-instagram-data)\n",
    "# Repository: https://github.com/do-me/fast-instagram-scraper\n",
    "# Contact: dominik@geo.rocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Concat all csv files in directory with powershell \n",
    "## (after mining data with [Fast Instagram Scraper](https://github.com/do-me/fast-instagram-scraper) )\n",
    "## Automatically taking care of headers and encoding \n",
    "\n",
    "```\n",
    "Get-ChildItem -Filter *.csv | Select-Object -ExpandProperty FullName | Import-Csv  -Encoding UTF8| Export-Csv .\\merged\\merged.csv -NoTypeInformation -Append -Encoding UTF8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Extract Hashtags and clean dataframe\n",
    "Note: this notebook was tested with a 120 mb csv file containing ~ 180 000 rows with post information. Everything worked flawlessly and fast (some seconds per cell on an i7 machine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import geopandas as gpd\n",
    "import shapely.wkt\n",
    "import pandas as pd \n",
    "from collections.abc import Iterable\n",
    "from ast import literal_eval\n",
    "import os \n",
    "os.environ['PROJ_LIB'] = 'C:/Users/username/Anaconda3/Library/share/proj' # change this file path if needed\n",
    "\n",
    "# load merged csv-file in pandas dataframe\n",
    "df = pd.read_csv(\"merged.csv\",encoding=\"utf-8\")\n",
    "\n",
    "# define some functions \n",
    "\n",
    "# cleaner, removes unnecessary upper nodes\n",
    "posts_without_text = 0 # just in case you can check later\n",
    "def str_to_obj(x):\n",
    "    global posts_without_text\n",
    "    try:\n",
    "        return literal_eval(x)[0][\"node\"][\"text\"]\n",
    "    except:\n",
    "        posts_without_text += 1\n",
    "        return \"\"\n",
    "\n",
    "# simple yet effective list flattener\n",
    "def flatten(l): #[[\"k\",\"k\"],\"k\"] -> ['k', 'k', 'k']\n",
    "    for el in l:\n",
    "        if isinstance(el, Iterable) and not isinstance(el, (str, bytes)):\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            yield el\n",
    "\n",
    "# some stop characters but could also be entire stopwords such as \"and\" or \"the\" - should be done later though\n",
    "stop_characters = [\"\",\" \"]\n",
    "\n",
    "# extracts hashtags from a string (see cell below for example)\n",
    "def extract_hashtags(x):\n",
    "    hashtags_space_separated = [i for i in x.split() if i.startswith(\"#\")] # normal hashtags #life #love -> #life, #love\n",
    "    hashtags_without_space = list(flatten([i.split(\"#\") if i.count(\"#\") > 1 else i for i in hashtags_space_separated])) # without space #life#love -> [#life, #love]\n",
    "    remove_hashtags = [i.replace(\"#\",\"\") for i in hashtags_without_space] # remove hashtags\n",
    "    remove_stop_characters = [i for i in remove_hashtags if i not in stop_characters] # remove empty items and space\n",
    "    return remove_stop_characters\n",
    "\n",
    "df[\"edge_media_to_caption.edges\"] = df[\"edge_media_to_caption.edges\"].apply(lambda x: str_to_obj(x)) # \"denode\" text\n",
    "df[\"hashtags\"] = df[\"edge_media_to_caption.edges\"].apply(lambda x: list(set(extract_hashtags(x)))) # extract unique hashtags by using set\n",
    "df[\"location_latlong_str\"] = df[\"location_latlong\"] # keep a column copy for later\n",
    "df # print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_hashtags(\"people look at this #amazing #super#fantastic #greenpark https://sample.com/#nohashtag this#hashtagwillbelost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_without_text/len(df) # in my case 8.5% without text and hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Create and export a simple geodataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create geodataframe from pandas dataframe\n",
    "\n",
    "# prepare some columns\n",
    "df[\"location_latlong\"] = df[\"location_latlong\"].apply(lambda x: literal_eval(x)) # convert to object\n",
    "df[\"lat\"] = df[\"location_latlong\"].apply(lambda x: x[0]) # new col lat\n",
    "df[\"long\"] = df[\"location_latlong\"].apply(lambda x: x[1]) # new col long\n",
    "\n",
    "# pandas df to geopanas gdf\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(y = df.lat, x = df.long))\n",
    "gdf.crs = (\"EPSG:4326\") # set EPSG information...\n",
    "gdf = gdf.to_crs(\"EPSG:3857\") # ...and reproject to web mercator\n",
    "\n",
    "# et voil√†: a nice, reprojected geodataframe\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeoJSON format cannot store object data types, so all columns must be plain numbers or strings\n",
    "\n",
    "# drop unnecessary column which cannot be saved due to list type\n",
    "gdf = gdf.drop(columns=['location_latlong'])\n",
    "\n",
    "# list to plain string \n",
    "gdf[\"hashtags\"] = gdf[\"hashtags\"].apply(', '.join)\n",
    "\n",
    "# save as GeoJSON but note that you have a GeoJSON with plenty of posts for the same points which might not be what you want\n",
    "gdf.to_file('all_posts_original.geojson', driver='GeoJSON', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Create geodataframe for unique points only without post information - small size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just unique locations coordinate, slug etc. but no post info\n",
    "# groupby does the trick here \n",
    "uf = df.groupby(['location_latlong_str','location_id','location_name','location_slug'], as_index=False).count()\n",
    "\n",
    "# rest as above\n",
    "uf = uf[[\"location_latlong_str\",\"location_id\",\"location_name\",\"location_slug\"]]\n",
    "uf[\"location_latlong_str\"] = uf[\"location_latlong_str\"].apply(lambda x: literal_eval(x)) # convert to object\n",
    "uf[\"lat\"] = uf[\"location_latlong_str\"].apply(lambda x: x[0]) \n",
    "uf[\"long\"] = uf[\"location_latlong_str\"].apply(lambda x: x[1])    \n",
    "ugdf = gpd.GeoDataFrame(uf, geometry=gpd.points_from_xy(y = uf.lat, x = uf.long))\n",
    "ugdf = ugdf.drop(columns=['location_latlong_str'])\n",
    "ugdf.crs = (\"EPSG:4326\")\n",
    "ugdf = ugdf.to_crs(\"EPSG:3857\")\n",
    "ugdf.to_file('unique_points_no_post_information.geojson', driver='GeoJSON', encoding=\"utf-8\")\n",
    "\n",
    "# for saving as geopackage\n",
    "# ugdf=ugdf.loc[ugdf.lat.notnull()] # if needed remove null values\n",
    "# ugdf[\"hashtags\"] = ugdf[\"hashtags\"].apply(', '.join) # can't save object, must be plain string\n",
    "# without_nan_ugdf.to_file(\"unique_points.gpkg\", layer='unique_points', driver=\"GPKG\") # throws error on Widnows but works nonetheless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Create geodataframe for unique points only with post information - large size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique coords and their posts, useful for filtering\n",
    "un = pd.DataFrame(df.groupby('location_latlong_str'))#.filter(lambda group: len(group) == 1)\n",
    "un[0] = un[0].apply(lambda x: literal_eval(x)) # convert to object\n",
    "un[\"lat\"] = un[0].apply(lambda x: x[0]) \n",
    "un[\"long\"] = un[0].apply(lambda x: x[1])    \n",
    "\n",
    "# dataframes in dataframe column 1\n",
    "un[1] = un[1].apply(lambda x: x.to_json()) # need to transform pandas dataframes to json \n",
    "\n",
    "postgdf = gpd.GeoDataFrame(un, geometry=gpd.points_from_xy(y = un.lat, x = un.long))\n",
    "\n",
    "postgdf = postgdf.drop(columns=[0])\n",
    "postgdf.crs = (\"EPSG:4326\")\n",
    "postgdf = postgdf.to_crs(\"EPSG:3857\")\n",
    "\n",
    "# rename columns\n",
    "postgdf.columns = [\"posts\",\"lat\",\"long\", \"geometry\"]\n",
    "postgdf.to_file('unique_points_with_post_information.geojson', driver='GeoJSON', encoding=\"utf-8\")\n",
    "postgdf\n",
    "# if AttributeError: 'int' object has no attribute 'encode' \n",
    "# column names cant be int must be str!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
